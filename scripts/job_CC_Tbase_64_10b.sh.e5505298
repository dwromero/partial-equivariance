wandb: Currently logged in as: tychovdo (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run clear-sponge-4808
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tychovdo/partial_equiv
wandb: üöÄ View run at https://wandb.ai/tychovdo/partial_equiv/runs/2rpp7t3x
wandb: Run data is saved locally in /var/tmp/pbs.5505298.pbs/outputs/2022-05-09/15-01-41/wandb/run-20220509_150143-2rpp7t3x
wandb: Run `wandb offline` to turn off syncing.
Error executing job with overrides: ['base_group.name=SE2', 'base_group.no_samples=1', 'base_group.sample_per_batch_element=False', 'base_group.sample_per_layer=False', 'base_group.sampling_method=deterministic', 'conv.bias=True', 'conv.padding=same', 'conv.cond_trans=True', 'dataset=CIFAR100', 'kernel.learn_omega0=False', 'kernel.no_hidden=64', 'kernel.no_layers=3', 'kernel.omega0=10', 'kernel.learn_omega1=False', 'kernel.omega1=10', 'kernel.size=7', 'kernel.type=SIREN', 'kernel.weight_norm=False', 'net.dropout=0', 'net.no_blocks=2', 'net.no_hidden=64', 'net.norm=BatchNorm', 'net.pool_blocks=[1,2]', 'net.block_width_factors=[1,1,2,1]', 'net.type=CKResNet', 'no_workers=3', 'seed=100', 'train.batch_size=64', 'train.do=True', 'train.epochs=300', 'train.lr=0.001', 'train.scheduler=cosine', 'train.scheduler_params.warmup_epochs=5', 'train.weight_decay=0.0', 'train.lr_probs=1e-4', 'conv.mask=False']
Traceback (most recent call last):
  File "/rds/general/user/tv21/home/partial-equivariance/main.py", line 78, in main
    dataloaders = construct_dataloaders(cfg)
  File "/rds/general/user/tv21/home/partial-equivariance/dataset_constructor.py", line 80, in construct_dataloaders
    training_set, validation_set, test_set = construct_dataset(cfg)
  File "/rds/general/user/tv21/home/partial-equivariance/dataset_constructor.py", line 46, in construct_dataset
    training_set = dataset(
  File "/rds/general/user/tv21/home/partial-equivariance/datasets/cifar100.py", line 47, in __init__
    super().__init__(root=root, train=train, transform=transform, download=True)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/cifar.py", line 66, in __init__
    self.download()
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/cifar.py", line 144, in download
    download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/utils.py", line 427, in download_and_extract_archive
    download_url(url, download_root, filename, md5)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/utils.py", line 130, in download_url
    url = _get_redirect_url(url, max_hops=max_redirect_hops)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/utils.py", line 78, in _get_redirect_url
    with urllib.request.urlopen(urllib.request.Request(url, headers=headers)) as response:
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 214, in urlopen
    return opener.open(url, data, timeout)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 523, in open
    response = meth(req, response)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 632, in http_response
    response = self.parent.error(
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 561, in error
    return self._call_chain(*args)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 494, in _call_chain
    result = func(*args)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 641, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 500: Internal Server Error

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Waiting for W&B process to finish, PID 4146920... (failed 1). Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run summary:
wandb:   no_params 3519684
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced clear-sponge-4808: https://wandb.ai/tychovdo/partial_equiv/runs/2rpp7t3x
wandb: Find logs at: ./outputs/2022-05-09/15-01-41/wandb/run-20220509_150143-2rpp7t3x/logs/debug.log
wandb: 
wandb: Currently logged in as: tychovdo (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run kind-pond-4810
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tychovdo/partial_equiv
wandb: üöÄ View run at https://wandb.ai/tychovdo/partial_equiv/runs/ezrp0ush
wandb: Run data is saved locally in /var/tmp/pbs.5505298.pbs/outputs/2022-05-09/15-03-49/wandb/run-20220509_150350-ezrp0ush
wandb: Run `wandb offline` to turn off syncing.
Error executing job with overrides: ['base_group.name=SE2', 'base_group.no_samples=1', 'base_group.sample_per_batch_element=False', 'base_group.sample_per_layer=False', 'base_group.sampling_method=deterministic', 'conv.bias=True', 'conv.padding=same', 'conv.cond_trans=True', 'dataset=CIFAR100', 'kernel.learn_omega0=False', 'kernel.no_hidden=64', 'kernel.no_layers=3', 'kernel.omega0=10', 'kernel.learn_omega1=False', 'kernel.omega1=10', 'kernel.size=7', 'kernel.type=SIREN', 'kernel.weight_norm=False', 'net.dropout=0', 'net.no_blocks=2', 'net.no_hidden=64', 'net.norm=BatchNorm', 'net.pool_blocks=[1,2]', 'net.block_width_factors=[1,1,2,1]', 'net.type=CKResNet', 'no_workers=3', 'seed=101', 'train.batch_size=64', 'train.do=True', 'train.epochs=300', 'train.lr=0.001', 'train.scheduler=cosine', 'train.scheduler_params.warmup_epochs=5', 'train.weight_decay=0.0', 'train.lr_probs=1e-4', 'conv.mask=False']
Traceback (most recent call last):
  File "/rds/general/user/tv21/home/partial-equivariance/main.py", line 78, in main
    dataloaders = construct_dataloaders(cfg)
  File "/rds/general/user/tv21/home/partial-equivariance/dataset_constructor.py", line 80, in construct_dataloaders
    training_set, validation_set, test_set = construct_dataset(cfg)
  File "/rds/general/user/tv21/home/partial-equivariance/dataset_constructor.py", line 46, in construct_dataset
    training_set = dataset(
  File "/rds/general/user/tv21/home/partial-equivariance/datasets/cifar100.py", line 47, in __init__
    super().__init__(root=root, train=train, transform=transform, download=True)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/cifar.py", line 66, in __init__
    self.download()
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/cifar.py", line 144, in download
    download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/utils.py", line 427, in download_and_extract_archive
    download_url(url, download_root, filename, md5)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/utils.py", line 130, in download_url
    url = _get_redirect_url(url, max_hops=max_redirect_hops)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torchvision/datasets/utils.py", line 78, in _get_redirect_url
    with urllib.request.urlopen(urllib.request.Request(url, headers=headers)) as response:
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 214, in urlopen
    return opener.open(url, data, timeout)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 523, in open
    response = meth(req, response)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 632, in http_response
    response = self.parent.error(
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 561, in error
    return self._call_chain(*args)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 494, in _call_chain
    result = func(*args)
  File "/rds/general/user/tv21/home/anaconda3/lib/python3.9/urllib/request.py", line 641, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 500: Internal Server Error

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: Waiting for W&B process to finish, PID 4149153... (failed 1). Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run summary:
wandb:   no_params 3519684
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced kind-pond-4810: https://wandb.ai/tychovdo/partial_equiv/runs/ezrp0ush
wandb: Find logs at: ./outputs/2022-05-09/15-03-49/wandb/run-20220509_150350-ezrp0ush/logs/debug.log
wandb: 
wandb: Currently logged in as: tychovdo (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run cool-feather-4812
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tychovdo/partial_equiv
wandb: üöÄ View run at https://wandb.ai/tychovdo/partial_equiv/runs/x5oecogg
wandb: Run data is saved locally in /var/tmp/pbs.5505298.pbs/outputs/2022-05-09/15-05-46/wandb/run-20220509_150547-x5oecogg
wandb: Run `wandb offline` to turn off syncing.
  0% 0/169001437 [00:00<?, ?it/s]  0% 33792/169001437 [00:00<15:28, 181991.07it/s]  0% 197632/169001437 [00:00<04:43, 594939.58it/s]  0% 623616/169001437 [00:00<01:36, 1737435.73it/s]  1% 1721344/169001437 [00:00<00:39, 4209769.02it/s]  2% 3589120/169001437 [00:00<00:22, 7468856.56it/s]  4% 7144448/169001437 [00:00<00:10, 15002643.32it/s]  6% 10713088/169001437 [00:00<00:07, 20733579.04it/s]  8% 14289920/169001437 [00:01<00:06, 24997062.25it/s] 11% 17875968/169001437 [00:01<00:05, 28116845.03it/s] 13% 21447680/169001437 [00:01<00:04, 30331799.48it/s] 15% 24708096/169001437 [00:01<00:05, 26438945.89it/s] 17% 28443648/169001437 [00:01<00:04, 29183532.38it/s] 19% 32015360/169001437 [00:01<00:04, 30962465.96it/s] 21% 35603456/169001437 [00:01<00:04, 32337932.71it/s] 23% 39175168/169001437 [00:01<00:03, 33297048.94it/s] 25% 42745856/169001437 [00:01<00:03, 33995885.57it/s] 27% 46203904/169001437 [00:02<00:04, 29371844.70it/s] 29% 49579008/169001437 [00:02<00:03, 30189379.63it/s] 31% 53216256/169001437 [00:02<00:03, 31812775.84it/s] 34% 56689664/169001437 [00:02<00:03, 32628820.81it/s] 36% 60277760/169001437 [00:02<00:03, 33553994.82it/s] 38% 63833088/169001437 [00:02<00:03, 34130166.16it/s] 40% 67404800/169001437 [00:02<00:02, 34587727.62it/s] 42% 70893568/169001437 [00:02<00:03, 30986205.04it/s] 44% 74155008/169001437 [00:02<00:03, 31340913.21it/s] 46% 77677568/169001437 [00:03<00:02, 32366043.68it/s] 48% 81019904/169001437 [00:03<00:02, 32519596.70it/s] 50% 84460544/169001437 [00:03<00:02, 33063861.93it/s] 52% 88032256/169001437 [00:03<00:02, 33629396.86it/s] 54% 91505664/169001437 [00:03<00:02, 33952008.19it/s] 56% 94916608/169001437 [00:03<00:02, 31984513.31it/s] 58% 98147328/169001437 [00:03<00:02, 31014407.19it/s] 60% 101532672/169001437 [00:03<00:02, 31685594.05it/s] 62% 105088000/169001437 [00:03<00:01, 32786861.54it/s] 64% 108594176/169001437 [00:03<00:01, 33049977.82it/s] 66% 112015360/169001437 [00:04<00:01, 33387281.79it/s] 68% 115573760/169001437 [00:04<00:01, 34024421.22it/s] 70% 118985728/169001437 [00:04<00:01, 33314948.34it/s] 72% 122326016/169001437 [00:04<00:01, 33190070.10it/s] 74% 125651968/169001437 [00:04<00:01, 32900104.80it/s] 76% 128946176/169001437 [00:04<00:01, 31781915.24it/s] 78% 132301824/169001437 [00:04<00:01, 32150346.67it/s] 80% 135595008/169001437 [00:04<00:01, 32288271.64it/s] 82% 139172864/169001437 [00:04<00:00, 33310407.79it/s] 84% 142511104/169001437 [00:04<00:00, 32962218.26it/s] 86% 145998848/169001437 [00:05<00:00, 33466732.52it/s] 88% 149472256/169001437 [00:05<00:00, 33807954.15it/s] 90% 152856576/169001437 [00:05<00:00, 33465692.70it/s] 92% 156206080/169001437 [00:05<00:00, 33198658.78it/s] 95% 159728640/169001437 [00:05<00:00, 33793420.60it/s] 97% 163110912/169001437 [00:05<00:00, 32366836.99it/s] 98% 166361088/169001437 [00:05<00:00, 32135761.10it/s]169001984it [00:05, 29299153.36it/s]                   
/rds/general/user/tv21/home/anaconda3/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
wandb: Network error (ReadTimeout), entering retry loop.
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
wandb: Network error (ReadTimeout), entering retry loop.
wandb: Network error (ReadTimeout), entering retry loop.
wandb: Network error (ReadTimeout), entering retry loop.
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
wandb: Network error (ReadTimeout), entering retry loop.
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
wandb: Network error (ReadTimeout), entering retry loop.
=>> PBS: job killed: walltime 172908 exceeded limit 172800
